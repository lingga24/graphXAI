{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42602452",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:GraphXAI-EdgeClassification:Dataset loaded.\n",
      "INFO:GraphXAI-EdgeClassification:Sampled edges: 20000\n",
      "INFO:GraphXAI-EdgeClassification:Unique nodes: 14679\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch_geometric.utils import subgraph\n",
    "from graphxai.gnn_models.node_classification import GCN_2layer\n",
    "import logging\n",
    "\n",
    "# Logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(\"GraphXAI-EdgeClassification\")\n",
    "\n",
    "# Load dataset\n",
    "data = torch.load('processed_data.pt')\n",
    "logger.info(\"Dataset loaded.\")\n",
    "\n",
    "# Get original edge_index and labels (truncate to 20k)\n",
    "edge_index = data['user', 'item'].edge_index[:, :20000]\n",
    "edge_label = data['user', 'item'].behavior[:20000]\n",
    "\n",
    "# Offset item indices\n",
    "offset = data['user'].num_nodes\n",
    "edge_index[1] += offset\n",
    "\n",
    "# Generate dummy features: one-hot only for sampled nodes\n",
    "all_nodes = torch.unique(edge_index)\n",
    "node_id_map = {nid.item(): i for i, nid in enumerate(all_nodes)}\n",
    "mapped_edge_index = torch.tensor([\n",
    "    [node_id_map[src.item()] for src in edge_index[0]],\n",
    "    [node_id_map[dst.item()] for dst in edge_index[1]]\n",
    "])\n",
    "\n",
    "x = torch.eye(len(all_nodes))  # one-hot for only the subgraph\n",
    "y = edge_label\n",
    "\n",
    "logger.info(f\"Sampled edges: {mapped_edge_index.shape[1]}\")\n",
    "logger.info(f\"Unique nodes: {x.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f014633",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:GraphXAI-EdgeClassification:Epoch 1, Loss: 1.5776\n",
      "INFO:GraphXAI-EdgeClassification:Epoch 2, Loss: 1.5080\n",
      "INFO:GraphXAI-EdgeClassification:Epoch 3, Loss: 1.5895\n",
      "INFO:GraphXAI-EdgeClassification:Epoch 4, Loss: 1.4216\n",
      "INFO:GraphXAI-EdgeClassification:Epoch 5, Loss: 1.4931\n",
      "INFO:GraphXAI-EdgeClassification:Epoch 6, Loss: 1.5907\n",
      "INFO:GraphXAI-EdgeClassification:Epoch 7, Loss: 1.3552\n",
      "INFO:GraphXAI-EdgeClassification:Epoch 8, Loss: 1.4333\n",
      "INFO:GraphXAI-EdgeClassification:Epoch 9, Loss: 1.3886\n",
      "INFO:GraphXAI-EdgeClassification:Epoch 10, Loss: 1.4315\n",
      "INFO:GraphXAI-EdgeClassification:Epoch 11, Loss: 1.4100\n",
      "INFO:GraphXAI-EdgeClassification:Epoch 12, Loss: 1.3657\n",
      "INFO:GraphXAI-EdgeClassification:Epoch 13, Loss: 1.4227\n",
      "INFO:GraphXAI-EdgeClassification:Epoch 14, Loss: 1.4348\n",
      "INFO:GraphXAI-EdgeClassification:Epoch 15, Loss: 1.5300\n",
      "INFO:GraphXAI-EdgeClassification:Epoch 16, Loss: 1.3882\n",
      "INFO:GraphXAI-EdgeClassification:Epoch 17, Loss: 1.4936\n",
      "INFO:GraphXAI-EdgeClassification:Epoch 18, Loss: 1.4824\n",
      "INFO:GraphXAI-EdgeClassification:Epoch 19, Loss: 1.4508\n",
      "INFO:GraphXAI-EdgeClassification:Epoch 20, Loss: 1.4093\n",
      "INFO:GraphXAI-EdgeClassification:Epoch 21, Loss: 1.3322\n",
      "INFO:GraphXAI-EdgeClassification:Epoch 22, Loss: 1.4681\n",
      "INFO:GraphXAI-EdgeClassification:Epoch 23, Loss: 1.4538\n",
      "INFO:GraphXAI-EdgeClassification:Epoch 24, Loss: 1.3800\n",
      "INFO:GraphXAI-EdgeClassification:Epoch 25, Loss: 1.4650\n",
      "INFO:GraphXAI-EdgeClassification:Epoch 26, Loss: 1.3404\n",
      "INFO:GraphXAI-EdgeClassification:Epoch 27, Loss: 1.4746\n",
      "INFO:GraphXAI-EdgeClassification:Epoch 28, Loss: 1.4030\n",
      "INFO:GraphXAI-EdgeClassification:Epoch 29, Loss: 1.4079\n",
      "INFO:GraphXAI-EdgeClassification:Epoch 30, Loss: 1.3891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.53      0.67     18035\n",
      "           1       0.00      0.00      0.00      1036\n",
      "           2       0.02      0.24      0.04       451\n",
      "           3       0.02      0.18      0.03       478\n",
      "\n",
      "    accuracy                           0.49     20000\n",
      "   macro avg       0.24      0.24      0.19     20000\n",
      "weighted avg       0.83      0.49      0.61     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Model\n",
    "# Misalnya x.shape[1] = 64 fitur input, hidden 32, output 4 class\n",
    "model = GCN_2layer(32, x.shape[1], 4).to(device)\n",
    "\n",
    "x = x.to(device)\n",
    "mapped_edge_index = mapped_edge_index.to(device)\n",
    "y = y.to(device)\n",
    "\n",
    "# Hitung class weight secara otomatis\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(edge_label.cpu().numpy()),\n",
    "    y=edge_label.cpu().numpy()\n",
    ")\n",
    "\n",
    "# Ubah ke tensor dan pindahkan ke device\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "\n",
    "# Gunakan di loss function\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training\n",
    "model.train()\n",
    "for epoch in range(1,31):\n",
    "    optimizer.zero_grad()\n",
    "    node_out = model(x, mapped_edge_index)\n",
    "    src, dst = mapped_edge_index\n",
    "    edge_feat = torch.cat([node_out[src], node_out[dst]], dim=1)\n",
    "    edge_out = nn.Linear(edge_feat.shape[1], 4).to(device)(edge_feat)\n",
    "    loss = criterion(edge_out, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    logger.info(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "if epoch % 5 == 0:\n",
    "    pred = edge_out.argmax(dim=1).detach().cpu().numpy()\n",
    "    true = y.cpu().numpy()\n",
    "    print(classification_report(true, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0ae75a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 18035, 1: 1036, 2: 451, 3: 478}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "unique, counts = np.unique(edge_label.cpu().numpy(), return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n",
    "\n",
    "# 0 = click, 1 = add to cart, 2 = buy, 3 = add to favorite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "36f84a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:EdgeClassification:Loading processed_data.pt...\n",
      "INFO:EdgeClassification:Dataset loaded successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset size: 100000 edges\n",
      "Edge index: tensor([[  48491,   48491,   48491,  ...,    8421,    8421,    8421],\n",
      "        [ 463421,  182135, 1060760,  ...,  374312,  784605,    7067]])\n",
      "Edge label: tensor([0, 0, 0,  ..., 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:EdgeClassification:Total nodes: 1148489\n",
      "INFO:EdgeClassification:User nodes: 49400\n",
      "INFO:EdgeClassification:Item nodes: 1099089\n",
      "INFO:EdgeClassification:Edge count (subset): 100000\n",
      "INFO:EdgeClassification:Feature dimension: 32\n",
      "INFO:EdgeClassification:Number of behavior classes: 4\n",
      "INFO:EdgeClassification:Model initialized with 4 output classes.\n",
      "INFO:EdgeClassification:Using balanced class weights: [ 0.27963582  4.5695486  11.51543     8.457375  ]\n",
      "INFO:EdgeClassification:Starting training...\n",
      "INFO:EdgeClassification:Epoch 10, Loss: 1.3766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (Epoch 10):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.26      0.40     89402\n",
      "           1       0.06      0.24      0.09      5471\n",
      "           2       0.03      0.45      0.06      2171\n",
      "           3       0.04      0.29      0.07      2956\n",
      "\n",
      "    accuracy                           0.26    100000\n",
      "   macro avg       0.26      0.31      0.16    100000\n",
      "weighted avg       0.82      0.26      0.37    100000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:EdgeClassification:Epoch 20, Loss: 1.3629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (Epoch 20):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.26      0.40     89402\n",
      "           1       0.06      0.26      0.10      5471\n",
      "           2       0.04      0.54      0.07      2171\n",
      "           3       0.05      0.30      0.08      2956\n",
      "\n",
      "    accuracy                           0.26    100000\n",
      "   macro avg       0.27      0.34      0.16    100000\n",
      "weighted avg       0.83      0.26      0.37    100000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:EdgeClassification:Epoch 30, Loss: 1.3469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (Epoch 30):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.32      0.48     89402\n",
      "           1       0.07      0.28      0.11      5471\n",
      "           2       0.04      0.49      0.07      2171\n",
      "           3       0.05      0.34      0.09      2956\n",
      "\n",
      "    accuracy                           0.33    100000\n",
      "   macro avg       0.27      0.36      0.19    100000\n",
      "weighted avg       0.83      0.33      0.44    100000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:EdgeClassification:Epoch 40, Loss: 1.3267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (Epoch 40):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.36      0.51     89402\n",
      "           1       0.07      0.30      0.12      5471\n",
      "           2       0.04      0.45      0.08      2171\n",
      "           3       0.06      0.41      0.10      2956\n",
      "\n",
      "    accuracy                           0.36    100000\n",
      "   macro avg       0.28      0.38      0.20    100000\n",
      "weighted avg       0.83      0.36      0.47    100000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:EdgeClassification:Epoch 50, Loss: 1.3031\n",
      "INFO:EdgeClassification:Training finished.\n",
      "INFO:EdgeClassification:Starting explanation generation using GraphLIME...\n",
      "INFO:EdgeClassification:Selected edge for explanation: User 28 -> Item 49405\n",
      "INFO:EdgeClassification:Subgraph extracted: 2 nodes, 0 edges\n",
      "INFO:EdgeClassification:No connecting edges found in the subgraph. Adding a dummy edge between the target nodes.\n",
      "INFO:EdgeClassification:Using node 0 (remapped from user 28) as target for explanation.\n",
      "/home/mlpc2/.local/lib/python3.8/site-packages/sklearn/linear_model/_base.py:116: FutureWarning: 'normalize' was deprecated in version 1.2 and will be removed in 1.4. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "INFO:EdgeClassification:Explanation generated using GraphLIME.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (Epoch 50):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.35      0.51     89402\n",
      "           1       0.08      0.31      0.12      5471\n",
      "           2       0.05      0.45      0.08      2171\n",
      "           3       0.06      0.47      0.11      2956\n",
      "\n",
      "    accuracy                           0.36    100000\n",
      "   macro avg       0.28      0.40      0.21    100000\n",
      "weighted avg       0.84      0.36      0.47    100000\n",
      "\n",
      "sub_nodes: tensor([   28, 49405], device='cuda:0')\n",
      "sub_edge_index: tensor([], device='cuda:0', size=(2, 0), dtype=torch.int64)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import k_hop_subgraph, to_networkx\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from graphxai.explainers import GraphLIME\n",
    "\n",
    "# -------------------- PART 1: DATA LOADING & PREPARATION --------------------\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(\"EdgeClassification\")\n",
    "\n",
    "logger.info(\"Loading processed_data.pt...\")\n",
    "try:\n",
    "    data = torch.load('processed_data.pt')\n",
    "    logger.info(\"Dataset loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    logger.error(\"Error: processed_data.pt not found. Please ensure the file is in the correct directory.\")\n",
    "    exit()\n",
    "\n",
    "# Use a subset of edges for efficiency (use up to 20,000 edges)\n",
    "num_available_edges = data['user', 'item'].edge_index.shape[1]\n",
    "subset_size = min(100_000, num_available_edges)\n",
    "edge_index = data['user', 'item'].edge_index[:, :subset_size]\n",
    "edge_label = data['user', 'item'].behavior[:subset_size]\n",
    "print(f\"Subset size: {subset_size} edges\")\n",
    "print(f\"Edge index: {edge_index}\")\n",
    "print(f\"Edge label: {edge_label}\")\n",
    "# Offset item indices globally (users first, then items)\n",
    "num_users = data['user'].num_nodes\n",
    "edge_index[1] += num_users\n",
    "\n",
    "# Create dummy features (random embeddings)\n",
    "num_items = data['item'].num_nodes\n",
    "num_nodes = num_users + num_items\n",
    "embedding_dim = 32\n",
    "x = torch.randn((num_nodes, embedding_dim))\n",
    "\n",
    "# Our task is edge classification; ensure labels are long integers.\n",
    "y = edge_label.long()\n",
    "\n",
    "logger.info(f\"Total nodes: {num_nodes}\")\n",
    "logger.info(f\"User nodes: {num_users}\")\n",
    "logger.info(f\"Item nodes: {num_items}\")\n",
    "logger.info(f\"Edge count (subset): {edge_index.shape[1]}\")\n",
    "logger.info(f\"Feature dimension: {embedding_dim}\")\n",
    "logger.info(f\"Number of behavior classes: {len(torch.unique(y))}\")\n",
    "\n",
    "# -------------------- PART 2: MODEL DEFINITION --------------------\n",
    "class GCN_2layer(nn.Module):\n",
    "    def __init__(self, hidden_channels, input_feat, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(input_feat, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.edge_mlp = nn.Sequential(\n",
    "            nn.Linear(2 * hidden_channels, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_channels, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, edge_index, edge_label_index):\n",
    "        # Compute node embeddings\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        # Concatenate embeddings for endpoints and predict edge class\n",
    "        src, dst = edge_label_index\n",
    "        edge_feat = torch.cat([x[src], x[dst]], dim=1)\n",
    "        return self.edge_mlp(edge_feat)\n",
    "    \n",
    "    # Helper method to return node embeddings (for node-level explanation)\n",
    "    def get_node_embeddings(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        return x\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "x = x.to(device)\n",
    "edge_index = edge_index.to(device)\n",
    "y = y.to(device)\n",
    "# For edge classification, we use the same edge_index as the label indices.\n",
    "edge_label_index = edge_index\n",
    "\n",
    "# Ensure number of classes is set correctly.\n",
    "num_classes = int(y.max().item() + 1)\n",
    "if num_classes <= 1:\n",
    "    logger.warning(f\"Only {num_classes} class found. Using at least 2 classes for CrossEntropyLoss.\")\n",
    "    num_classes = 2\n",
    "\n",
    "model = GCN_2layer(32, x.shape[1], num_classes).to(device)\n",
    "logger.info(f\"Model initialized with {num_classes} output classes.\")\n",
    "\n",
    "# Compute balanced class weights if more than one class is present.\n",
    "y_np = y.cpu().numpy()\n",
    "unique_classes = np.unique(y_np)\n",
    "if len(unique_classes) > 1:\n",
    "    class_weights = compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=unique_classes,\n",
    "        y=y_np\n",
    "    )\n",
    "    class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "    logger.info(f\"Using balanced class weights: {class_weights_tensor.cpu().numpy()}\")\n",
    "else:\n",
    "    logger.warning(\"Only one class in labels; using default CrossEntropyLoss.\")\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# -------------------- PART 3: TRAINING --------------------\n",
    "logger.info(\"Starting training...\")\n",
    "model.train()\n",
    "num_epochs = 50\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(x, edge_index, edge_index)\n",
    "    loss = criterion(out, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        logger.info(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
    "        pred = out.argmax(dim=1).detach().cpu().numpy()\n",
    "        true = y.cpu().numpy()\n",
    "        print(f\"Classification Report (Epoch {epoch}):\")\n",
    "        print(classification_report(true, pred, zero_division=0))\n",
    "\n",
    "logger.info(\"Training finished.\")\n",
    "\n",
    "# -------------------- PART 4: EXPLANATION & SUBGRAPH EXTRACTION --------------------\n",
    "logger.info(\"Starting explanation generation using GraphLIME...\")\n",
    "\n",
    "# Choose a target user–item pair for our question \"Will user X buy item Y?\"\n",
    "# (Ensure user_x is within [0, num_users-1] and item_y is within [num_users, num_nodes-1])\n",
    "user_x = 28\n",
    "item_y_local = 5  # e.g. 6th item among items\n",
    "item_y = num_users + item_y_local\n",
    "logger.info(f\"Selected edge for explanation: User {user_x} -> Item {item_y}\")\n",
    "\n",
    "# To capture more connectivity, extract a 3-hop subgraph around these nodes.\n",
    "sub_nodes, sub_edge_index, mapping, _ = k_hop_subgraph(\n",
    "    node_idx=[user_x, item_y],\n",
    "    num_hops=5,\n",
    "    edge_index=edge_index,\n",
    "    relabel_nodes=True,\n",
    "    num_nodes=x.shape[0]\n",
    ")\n",
    "logger.info(f\"Subgraph extracted: {len(sub_nodes)} nodes, {sub_edge_index.shape[1]} edges\")\n",
    "print(\"sub_nodes:\", sub_nodes)\n",
    "print(\"sub_edge_index:\", sub_edge_index)\n",
    "\n",
    "# Create a PyG Data object for the subgraph.\n",
    "sub_data = Data(x=x[sub_nodes], edge_index=sub_edge_index)\n",
    "# Add a 'nodes' attribute required for visualization.\n",
    "sub_data.nodes = list(range(sub_data.num_nodes))\n",
    "\n",
    "# (Optional) If no connecting edges exist in the extracted subgraph, add a dummy edge.\n",
    "if sub_data.edge_index.numel() == 0:\n",
    "    logger.info(\"No connecting edges found in the subgraph. Adding a dummy edge between the target nodes.\")\n",
    "    sub_data.edge_index = torch.tensor([[0], [1]], dtype=torch.long, device=device)\n",
    "\n",
    "# Since GraphLIME explains nodes, choose one of the target nodes to explain.\n",
    "# Here we explain the user node. The remapped index for user_x is taken from the mapping.\n",
    "node_target = mapping[0].item()\n",
    "logger.info(f\"Using node {node_target} (remapped from user {user_x}) as target for explanation.\")\n",
    "\n",
    "# GraphLIME requires a label tensor for the nodes.\n",
    "# Since we are not performing node classification, we supply a dummy 2D label tensor.\n",
    "dummy_y = torch.zeros((sub_data.num_nodes, 1), dtype=torch.float32).to(device)\n",
    "\n",
    "# Initialize GraphLIME explainer and get the explanation for the target node.\n",
    "explainer = GraphLIME(model=model)\n",
    "exp = explainer.get_explanation_node(\n",
    "    node_idx=node_target,\n",
    "    x=sub_data.x,\n",
    "    edge_index=sub_data.edge_index,\n",
    "    forward_kwargs={'edge_label_index': sub_data.edge_index},\n",
    "    y=dummy_y\n",
    ")\n",
    "logger.info(\"Explanation generated using GraphLIME.\")\n",
    "\n",
    "# Set the explanation’s subgraph to our sub_data.\n",
    "exp.enc_subgraph = sub_data\n",
    "\n",
    "# -------------------- PART 5: CUSTOM VISUALIZATION FUNCTION --------------------\n",
    "def custom_visualize_explanation(exp, ax=None, show=True):\n",
    "    \"\"\"\n",
    "    Custom visualization:\n",
    "      - Convert exp.enc_subgraph (a PyG Data object) to an undirected NetworkX graph.\n",
    "      - Color nodes according to explanation importance (if available; else uniform).\n",
    "      - Draw using a spring layout.\n",
    "    \"\"\"\n",
    "    # Convert subgraph to NetworkX graph.\n",
    "    G = to_networkx(exp.enc_subgraph, to_undirected=True)\n",
    "    # Create an identity mapping from nodes in sub_data.\n",
    "    node_map = {n: n for n in exp.enc_subgraph.nodes}\n",
    "    \n",
    "    # Try to retrieve node importance scores from the explanation.\n",
    "    try:\n",
    "        # exp.node_imp should be a tensor of shape (num_nodes_in_subgraph, ...)\n",
    "        importance = exp.node_imp.detach().cpu().numpy().flatten()\n",
    "    except Exception:\n",
    "        importance = np.ones(len(G.nodes()))\n",
    "    \n",
    "    # Map importance to each node.\n",
    "    node_colors = []\n",
    "    for n in G.nodes():\n",
    "        if n < len(importance):\n",
    "            node_colors.append(importance[n])\n",
    "        else:\n",
    "            node_colors.append(0.0)\n",
    "    \n",
    "    # Normalize importance values.\n",
    "    norm = plt.Normalize(vmin=min(node_colors), vmax=max(node_colors))\n",
    "    cmap = plt.get_cmap(\"viridis\")\n",
    "    colors = [cmap(norm(val)) for val in node_colors]\n",
    "    \n",
    "    # Compute a spring layout.\n",
    "    pos = nx.spring_layout(G, seed=42)\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    nx.draw(G, pos, with_labels=True, node_color=colors, ax=ax, node_size=500, font_size=8)\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])\n",
    "    plt.colorbar(sm, ax=ax)\n",
    "    if show:\n",
    "        plt.show()\n",
    "\n",
    "# -------------------- PART 6: VISUALIZE THE EXPLANATION --------------------\n",
    "custom_visualize_explanation(exp, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "46b70dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target edge exists in subset: False\n"
     ]
    }
   ],
   "source": [
    "# Assume user_x and item_y are defined (note: item_y is the global index after offset)\n",
    "target_edge_exists = ((edge_index[0] == user_x) & (edge_index[1] == item_y)).sum() > 0\n",
    "print(\"Target edge exists in subset:\", target_edge_exists.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "24c76c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Case2_ItemInfluence:Loading processed_data.pt...\n",
      "INFO:Case2_ItemInfluence:Dataset loaded successfully.\n",
      "INFO:Case2_ItemInfluence:Using a subset of 100000 user-item edges.\n",
      "INFO:Case2_ItemInfluence:Number of active users in subset: 974\n",
      "INFO:Case2_ItemInfluence:User 61 has 89 interactions.\n",
      "INFO:Case2_ItemInfluence:User 64 has 76 interactions.\n",
      "INFO:Case2_ItemInfluence:User 67 has 33 interactions.\n",
      "INFO:Case2_ItemInfluence:User 68 has 101 interactions.\n",
      "INFO:Case2_ItemInfluence:User 73 has 59 interactions.\n",
      "INFO:Case2_ItemInfluence:Selected target user: 49239 (highest count: 607)\n",
      "INFO:Case2_ItemInfluence:Extracted subgraph: 1 nodes, 0 edges\n",
      "WARNING:Case2_ItemInfluence:Extracted subgraph has no edges; the target user may be isolated in the subset. Consider increasing subset size or choosing another user.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgraph nodes: tensor([49239], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain node 0: 100%|██████████| 100/100 [00:00<00:00, 179.49it/s]\n",
      "INFO:Case2_ItemInfluence:GNNExplainer finished for target user node.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GNNExplainer\n",
    "from torch_geometric.utils import k_hop_subgraph, to_networkx\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "# -------------------- PART 1: DATA LOADING & PREPARATION --------------------\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(\"Case2_ItemInfluence\")\n",
    "\n",
    "logger.info(\"Loading processed_data.pt...\")\n",
    "try:\n",
    "    proc_data = torch.load('processed_data.pt')\n",
    "    logger.info(\"Dataset loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    logger.error(\"processed_data.pt not found. Please ensure the file is in the correct directory.\")\n",
    "    exit()\n",
    "\n",
    "# We assume that proc_data is a HeteroData object.\n",
    "# We use the user-item edge for our graph.\n",
    "# In the processing script, items have not been offset,\n",
    "# so we do the offset here:\n",
    "user_item_edge_index = proc_data['user', 'item'].edge_index.clone()\n",
    "num_users = proc_data['user'].num_nodes\n",
    "# Offset: add num_users to each item index.\n",
    "user_item_edge_index[1] += num_users\n",
    "\n",
    "# For our experiments we select a subset of edges – for instance 100k, if available.\n",
    "num_available_edges = user_item_edge_index.shape[1]\n",
    "subset_size = min(100_000, num_available_edges)\n",
    "user_item_edge_index = user_item_edge_index[:, :subset_size]\n",
    "logger.info(f\"Using a subset of {subset_size} user-item edges.\")\n",
    "\n",
    "# Create dummy node features for all nodes (users + items).\n",
    "num_items = proc_data['item'].num_nodes\n",
    "num_nodes = num_users + num_items\n",
    "embedding_dim = 32\n",
    "x = torch.randn((num_nodes, embedding_dim))\n",
    "\n",
    "# -------------------- PART 2: MODEL DEFINITION (for embedding extraction) --------------------\n",
    "class GCN_2layer(nn.Module):\n",
    "    def __init__(self, hidden_channels, input_feat):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(input_feat, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        return x\n",
    "    \n",
    "    def get_node_embeddings(self, x, edge_index):\n",
    "        return self.forward(x, edge_index)\n",
    "    \n",
    "# We only need embeddings for the explanation in Case 2.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "x = x.to(device)\n",
    "user_item_edge_index = user_item_edge_index.to(device)\n",
    "\n",
    "# For demonstration, we initialize the model with random weights.\n",
    "model = GCN_2layer(32, embedding_dim).to(device)\n",
    "model.eval()  # For explanation, we only need a forward pass.\n",
    "\n",
    "# -------------------- PART 3: SELECTING A TARGET USER --------------------\n",
    "# Check which users are active in the current subset:\n",
    "active_users, counts = torch.unique(user_item_edge_index[0], return_counts=True)\n",
    "logger.info(f\"Number of active users in subset: {active_users.numel()}\")\n",
    "\n",
    "# Print out a few active users and their counts (for debug)\n",
    "for i in range(min(5, active_users.numel())):\n",
    "    logger.info(f\"User {active_users[i].item()} has {counts[i].item()} interactions.\")\n",
    "\n",
    "# Select a target user with a high number of interactions.\n",
    "max_idx = counts.argmax().item()\n",
    "target_user = active_users[max_idx].item()\n",
    "logger.info(f\"Selected target user: {target_user} (highest count: {counts[max_idx].item()})\")\n",
    "\n",
    "# -------------------- PART 4: EXTRACTING A SUBGRAPH AROUND THE TARGET USER --------------------\n",
    "# Use k_hop_subgraph on the user-item edge index.\n",
    "# Here we extract a 2-hop subgraph around the target user.\n",
    "sub_nodes, sub_edge_index, mapping, _ = k_hop_subgraph(\n",
    "    node_idx=[target_user],\n",
    "    num_hops=2,\n",
    "    edge_index=user_item_edge_index,\n",
    "    relabel_nodes=True,\n",
    "    num_nodes=num_nodes\n",
    ")\n",
    "logger.info(f\"Extracted subgraph: {len(sub_nodes)} nodes, {sub_edge_index.shape[1]} edges\")\n",
    "print(\"Subgraph nodes:\", sub_nodes)\n",
    "\n",
    "# If no edges are found, log a warning.\n",
    "if sub_edge_index.shape[1] == 0:\n",
    "    logger.warning(\"Extracted subgraph has no edges; the target user may be isolated in the subset. Consider increasing subset size or choosing another user.\")\n",
    "\n",
    "# Create a PyG Data object for the subgraph.\n",
    "user_sub_data = Data(x=x[sub_nodes], edge_index=sub_edge_index)\n",
    "user_sub_data.nodes = list(range(user_sub_data.num_nodes))\n",
    "\n",
    "# -------------------- PART 5: NODE EXPLANATION USING GNNExplainer --------------------\n",
    "# GNNExplainer in your code expects a model with .eval() and .forward() methods.\n",
    "# Since our node explanation is based on the node embeddings, we wrap the get_node_embeddings call.\n",
    "class NodeForwardWrapper(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "    def forward(self, x, edge_index):\n",
    "        return self.model.get_node_embeddings(x, edge_index)\n",
    "\n",
    "node_wrapper = NodeForwardWrapper(model).to(device)\n",
    "\n",
    "# Initialize the GNNExplainer with the wrapper.\n",
    "explainer_user = GNNExplainer(model=node_wrapper)\n",
    "try:\n",
    "    # mapping gives the remapped index of the original target user in the subgraph.\n",
    "    target_user_sub = mapping[0].item()  # Assumes mapping[0] corresponds to target_user.\n",
    "    node_feat_mask, edge_mask = explainer_user.explain_node(\n",
    "        node_idx=target_user_sub,\n",
    "        x=user_sub_data.x,\n",
    "        edge_index=user_sub_data.edge_index\n",
    "    )\n",
    "    logger.info(\"GNNExplainer finished for target user node.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"GNNExplainer failed: {e}\")\n",
    "\n",
    "# -------------------- PART 6: VISUALIZE THE EXPLANATION --------------------\n",
    "def custom_visualize_node_explanation(G, target_idx, title=\"Node Explanation\"):\n",
    "    \"\"\"\n",
    "    Visualize a NetworkX graph G with the target node (target_idx) highlighted in red.\n",
    "    \"\"\"\n",
    "    pos = nx.spring_layout(G, seed=42)\n",
    "    node_colors = []\n",
    "    for n in G.nodes():\n",
    "        if n == target_idx:\n",
    "            node_colors.append(\"red\")\n",
    "        else:\n",
    "            node_colors.append(\"skyblue\")\n",
    "    nx.draw(G, pos, with_labels=True, node_color=node_colors, node_size=500, font_size=8)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Convert the subgraph to a NetworkX graph.\n",
    "G_user = to_networkx(user_sub_data, to_undirected=True)\n",
    "target_user_local = mapping[0].item()  # remapped target user index in subgraph.\n",
    "custom_visualize_node_explanation(G_user, target_user_local, title=\"Case 2: Explanation for Active User\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphxai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
