{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35231dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Processing to homogeneous graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:  Number of unique users     : 35360\n",
      "INFO:__main__:Selected 490128 interactions on 2017-11-28\n",
      "INFO:__main__:Graph Summary:\n",
      "INFO:__main__:  Number of item nodes     : 253988\n",
      "INFO:__main__:  Number of item-item edges: 11057360\n",
      "INFO:__main__:  Number of node features  : 1\n",
      "INFO:__main__:  Number of classes        : 2\n",
      "INFO:__main__:  Class distribution       : [244298, 9690]\n",
      "INFO:__main__:  Train/Val/Test splits    : 152392/50798/50798\n",
      "INFO:__main__:Saved homogeneous graph: filtered_graph_2017-11-28.pt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_sparse import coalesce\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def manage_memory():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "def process_data_to_homogeneous_graph(dataset_path, selected_day='2017-11-28'):\n",
    "    logger.info(\"Processing to homogeneous graph...\")\n",
    "\n",
    "    try:\n",
    "        # Load dataset\n",
    "        df = pd.read_csv(dataset_path)\n",
    "        df['Timestamp'] = pd.to_datetime(df['Timestamp'], unit='s')\n",
    "\n",
    "        # Filter only for selected date\n",
    "        selected_day = datetime.strptime(selected_day, '%Y-%m-%d').date()\n",
    "        df = df[df['Timestamp'].dt.date == selected_day]\n",
    "\n",
    "        num_users = df['User_ID'].nunique()\n",
    "        logger.info(f\"  Number of unique users     : {num_users}\")\n",
    "\n",
    "        if df.empty:\n",
    "            raise ValueError(f\"No data found for selected date: {selected_day}\")\n",
    "\n",
    "        logger.info(f\"Selected {len(df)} interactions on {selected_day}\")\n",
    "\n",
    "        # Encode behaviors\n",
    "        behavior_dict = {'PageView': 0, 'AddToCart': 1, 'Buy': 2, 'Favorite': 3}\n",
    "        df['Behavior'] = df['Behavior'].map(behavior_dict)\n",
    "\n",
    "        # Encode IDs\n",
    "        for col in ['User_ID', 'Product_ID', 'Category_ID']:\n",
    "            df[col], _ = pd.factorize(df[col])\n",
    "\n",
    "        num_items = df['Product_ID'].nunique()\n",
    "\n",
    "        # === Step 1: Create item-item edges via co-interaction (same user interacted with both items)\n",
    "        user_to_items = defaultdict(set)\n",
    "        for u, i in zip(df['User_ID'], df['Product_ID']):\n",
    "            user_to_items[u].add(i)\n",
    "\n",
    "        edge_list = []\n",
    "        for items in user_to_items.values():\n",
    "            for i1, i2 in itertools.combinations(items, 2):\n",
    "                edge_list.append((i1, i2))\n",
    "                edge_list.append((i2, i1))  # undirected\n",
    "\n",
    "        edge_index = torch.tensor(edge_list, dtype=torch.long).t().contiguous()\n",
    "        edge_index, _ = coalesce(edge_index, None, num_items, num_items)  # remove duplicates\n",
    "\n",
    "        # === Step 2: Create node labels (item.y)\n",
    "        item_labels = torch.zeros(num_items, dtype=torch.long)\n",
    "        buy_items = df[df['Behavior'] == 2]['Product_ID'].unique()\n",
    "        item_labels[torch.tensor(buy_items)] = 1\n",
    "\n",
    "        # === Step 3: Create node features (e.g., interaction count per item)\n",
    "        item_degree = df['Product_ID'].value_counts().sort_index()\n",
    "        item_degree = torch.tensor(item_degree.values, dtype=torch.float).unsqueeze(1)  # shape [N, 1]\n",
    "\n",
    "        # === Step 4: Train/val/test masks\n",
    "        all_items = torch.arange(num_items)\n",
    "        train_idx, temp_idx = train_test_split(all_items, test_size=0.4, random_state=42, stratify=item_labels)\n",
    "        val_idx, test_idx = train_test_split(temp_idx, test_size=0.5, random_state=42, stratify=item_labels[temp_idx])\n",
    "\n",
    "        train_mask = torch.zeros(num_items, dtype=torch.bool)\n",
    "        val_mask = torch.zeros(num_items, dtype=torch.bool)\n",
    "        test_mask = torch.zeros(num_items, dtype=torch.bool)\n",
    "        train_mask[train_idx] = True\n",
    "        val_mask[val_idx] = True\n",
    "        test_mask[test_idx] = True\n",
    "\n",
    "        # === Step 5: Build final Data object\n",
    "        data = Data(\n",
    "            x=item_degree,\n",
    "            edge_index=edge_index,\n",
    "            y=item_labels,\n",
    "            train_mask=train_mask,\n",
    "            val_mask=val_mask,\n",
    "            test_mask=test_mask\n",
    "        )\n",
    "\n",
    "        # === Step 6: Print graph statistics ===\n",
    "        num_nodes = data.num_nodes\n",
    "        num_edges = data.num_edges\n",
    "        num_features = data.num_node_features\n",
    "        num_classes = int(item_labels.max().item()) + 1\n",
    "        class_counts = torch.bincount(item_labels)\n",
    "\n",
    "        logger.info(f\"Graph Summary:\")\n",
    "        logger.info(f\"  Number of item nodes     : {num_nodes}\")\n",
    "        logger.info(f\"  Number of item-item edges: {num_edges}\")\n",
    "        logger.info(f\"  Number of node features  : {num_features}\")\n",
    "        logger.info(f\"  Number of classes        : {num_classes}\")\n",
    "        logger.info(f\"  Class distribution       : {class_counts.tolist()}\")\n",
    "        logger.info(f\"  Train/Val/Test splits    : {train_mask.sum().item()}/{val_mask.sum().item()}/{test_mask.sum().item()}\")\n",
    "\n",
    "        torch.save(data, f'filtered_graph_{selected_day}.pt')\n",
    "        logger.info(f\"Saved homogeneous graph: filtered_graph_{selected_day}.pt\")\n",
    "\n",
    "        manage_memory()\n",
    "        return data\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Processing error: {e}\")\n",
    "        return None\n",
    "\n",
    "# === Run the processing ===\n",
    "dataset_path = 'UserBehavior_5M_cleaned.csv'\n",
    "if os.path.exists(dataset_path):\n",
    "    processed_data = process_data_to_homogeneous_graph(dataset_path, selected_day='2017-11-28')\n",
    "else:\n",
    "    logger.error(f\"Dataset not found at {dataset_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphxai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
